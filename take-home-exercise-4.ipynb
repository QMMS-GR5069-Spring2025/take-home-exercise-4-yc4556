{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "725fbbe7-5352-4233-bb4d-c41561147f9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1805cce7-7617-4d76-b497-c54cab9eaf2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "f1_data = pd.read_csv(\"/dbfs/FileStore/tables/results-1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "328cf84a-1f4f-454d-86a7-5faa06d5cd38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(   grid  constructorId\n",
       " 0     1              1\n",
       " 1     5              2\n",
       " 2     7              3\n",
       " 3    11              4\n",
       " 4     3              1,\n",
       " 0    1\n",
       " 1    2\n",
       " 2    3\n",
       " 3    4\n",
       " 4    5\n",
       " Name: positionOrder, dtype: int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select features and target for prediction\n",
    "features = ['grid', 'constructorId']  # Features we use for prediction\n",
    "target = 'positionOrder'              # What we want to predict\n",
    "\n",
    "X = f1_data[features]\n",
    "y = f1_data[target]\n",
    "\n",
    "# Display the first few rows of features and target\n",
    "X.head(), y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce263d78-5e68-48c6-bd26-2e69307f5bbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((20069, 2), (6690, 2), (20069,), (6690,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Display the shape of the resulting sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b35e50d-6ca8-4725-ac14-3826adb99f65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n2025/04/29 01:49:35 WARNING mlflow.models.model: Model logged without a signature. Signatures will be required for upcoming model registry features as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.15.1/models.html#set-signature-on-logged-model for instructions on setting a model signature on your logged model.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bff9b0c393a4f499227caeaa4b6af08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/29 01:49:36 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n2025/04/29 01:49:36 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run Logistic Regression at: columbiau-gr5069.cloud.databricks.com/ml/experiments/743188476171287/runs/a5dc4cdbc16b4492ad6f0ea766b88b3d.\n2025/04/29 01:49:36 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: columbiau-gr5069.cloud.databricks.com/ml/experiments/743188476171287.\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression model\n",
    "with mlflow.start_run(run_name=\"Logistic Regression\"):\n",
    "    model1 = LogisticRegression(max_iter=1000)\n",
    "    model1.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred1 = model1.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc1 = accuracy_score(y_test, y_pred1)\n",
    "    prec1 = precision_score(y_test, y_pred1, average='weighted', zero_division=0)\n",
    "    rec1 = recall_score(y_test, y_pred1, average='weighted', zero_division=0)\n",
    "    f1_1 = f1_score(y_test, y_pred1, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", acc1)\n",
    "    mlflow.log_metric(\"precision\", prec1)\n",
    "    mlflow.log_metric(\"recall\", rec1)\n",
    "    mlflow.log_metric(\"f1_score\", f1_1)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model1, \"logistic_regression_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae373d66-ec90-4c6c-84fb-469e4f2e7476",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/29 01:50:35 WARNING mlflow.models.model: Model logged without a signature. Signatures will be required for upcoming model registry features as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.15.1/models.html#set-signature-on-logged-model for instructions on setting a model signature on your logged model.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5736da94694f0ea9b3a78cae3dd626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/29 01:50:36 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n2025/04/29 01:50:36 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run Decision Tree at: columbiau-gr5069.cloud.databricks.com/ml/experiments/743188476171287/runs/66d622ab35f84e3b805bf245d98f5081.\n2025/04/29 01:50:36 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: columbiau-gr5069.cloud.databricks.com/ml/experiments/743188476171287.\n"
     ]
    }
   ],
   "source": [
    "# Train a Decision Tree Classifier\n",
    "with mlflow.start_run(run_name=\"Decision Tree\"):\n",
    "    model2 = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "    model2.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred2 = model2.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc2 = accuracy_score(y_test, y_pred2)\n",
    "    prec2 = precision_score(y_test, y_pred2, average='weighted', zero_division=0)\n",
    "    rec2 = recall_score(y_test, y_pred2, average='weighted', zero_division=0)\n",
    "    f1_2 = f1_score(y_test, y_pred2, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", acc2)\n",
    "    mlflow.log_metric(\"precision\", prec2)\n",
    "    mlflow.log_metric(\"recall\", rec2)\n",
    "    mlflow.log_metric(\"f1_score\", f1_2)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model2, \"decision_tree_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76be23bf-78de-450e-b669-80fa939625cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a database if not already exist\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS student_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17dd3101-369d-4937-9211-7ee5871813d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the database\n",
    "spark.sql(\"USE student_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01c5b0a6-75dc-4235-95a5-34ccaf113b61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS model1_predictions (\n",
    "    id INT,\n",
    "    prediction DOUBLE\n",
    ")\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15fa543e-2a9e-4513-9011-0c1494d391d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS model2_predictions (\n",
    "    id INT,\n",
    "    prediction DOUBLE\n",
    ")\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e6be214-2666-4b14-8192-c59f2567206c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Prepare predictions from Logistic Regression model\n",
    "import numpy as np\n",
    "\n",
    "predictions_df1 = pd.DataFrame({\n",
    "    'id': np.arange(len(y_pred)),  # <-- fix id to be 0,1,2,...\n",
    "    'prediction': y_pred\n",
    "})\n",
    "\n",
    "# Convert to Spark DataFrame\n",
    "spark_df1 = spark.createDataFrame(predictions_df1)\n",
    "\n",
    "# Save into the first table\n",
    "spark_df1.write.mode(\"overwrite\").saveAsTable(\"model1_predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac2a810c-fd5d-4a53-9fa3-82c375becca7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Prepare predictions from Decision Tree model\n",
    "predictions_df2 = pd.DataFrame({\n",
    "    'id': np.arange(len(y_pred2)),  # <-- generate id from 0,1,2,...\n",
    "    'prediction': y_pred2\n",
    "})\n",
    "\n",
    "# Convert to Spark DataFrame\n",
    "spark_df2 = spark.createDataFrame(predictions_df2)\n",
    "\n",
    "# Save into the second table\n",
    "spark_df2.write.mode(\"overwrite\").saveAsTable(\"model2_predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ded51f4-c4fb-4454-8170-2d09c00ff618",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n| id|prediction|\n+---+----------+\n|  0|         0|\n|  1|         0|\n+---+----------+\n\n+---+----------+\n| id|prediction|\n+---+----------+\n|  0|         3|\n|  1|         1|\n|  2|        15|\n|  3|         5|\n|  4|        15|\n+---+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Check first table\n",
    "spark.sql(\"SELECT * FROM model1_predictions LIMIT 5\").show()\n",
    "\n",
    "# Check second table\n",
    "spark.sql(\"SELECT * FROM model2_predictions LIMIT 5\").show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "take-home-exercise-4",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}